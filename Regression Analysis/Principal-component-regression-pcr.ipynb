{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30775,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Principal Component Regression (PCR)","metadata":{}},{"cell_type":"markdown","source":"Principal Component Regression (PCR) combines Principal Component Analysis (PCA) with linear regression. It is particularly useful when dealing with multicollinearity in datasets, as it reduces the dimensionality of the data by transforming correlated variables into a set of linearly uncorrelated components.","metadata":{}},{"cell_type":"code","source":"# Principal Component Regression (PCR) Notebook\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\n# Generate synthetic data\nnp.random.seed(0)\nX = 2 - 3 * np.random.rand(100)\ny = X**2 + np.random.randn(100) * 0.5\n\n# Reshape the data\nX = X[:, np.newaxis]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n# Create polynomial features\npoly = PolynomialFeatures(degree=2)\nX_poly = poly.fit_transform(X_train)\n\n# Apply PCA to the polynomial features\npca = PCA(n_components=1)  # Adjust the number of components based on explained variance\nX_pca = pca.fit_transform(X_poly)\n\n# Train the linear regression model on PCA-transformed features\nmodel = LinearRegression()\nmodel.fit(X_pca, y_train)\n\n# Predict using the model\nX_test_poly = poly.transform(X_test)\nX_test_pca = pca.transform(X_test_poly)\ny_pred = model.predict(X_test_pca)\n\n# Visualize the results\nplt.scatter(X_test, y_test, color='red', label='Actual data')\nplt.scatter(X_test, y_pred, color='blue', label='Predicted data')\nplt.title('Principal Component Regression Results')\nplt.xlabel('X')\nplt.ylabel('y')\nplt.legend()\nplt.show()\n\n# Calculate and print model performance metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(\"Model Performance Metrics:\")\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"R-squared (R²): {r2}\")\n\n# Print explained variance ratio of the principal components\nprint(\"Explained variance ratio of the principal components:\", pca.explained_variance_ratio_)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T05:56:00.509391Z","iopub.execute_input":"2024-10-01T05:56:00.509841Z","iopub.status.idle":"2024-10-01T05:56:01.807015Z","shell.execute_reply.started":"2024-10-01T05:56:00.509795Z","shell.execute_reply":"2024-10-01T05:56:01.805748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Explanation of Code Components\n\n1. **Data Generation**: Similar to previous examples, synthetic data is generated for polynomial regression.\n\n2. **Data Preprocessing**: The dataset is split into training and testing sets, and polynomial features are created.\n\n3. **PCA Transformation**: PCA is applied to the polynomial features to reduce dimensionality. You can adjust the number of components in `PCA(n_components=1)` based on the desired level of variance explained.\n\n4. **Model Training**: A linear regression model is trained on the PCA-transformed features.\n\n5. **Prediction**: Predictions are made on the test set.\n\n6. **Visualization**: A scatter plot shows the actual vs. predicted values.\n\n7. **Performance Measurement**: Model performance is evaluated using Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (R²) metrics.\n\n8. **Explained Variance**: The explained variance ratio of the principal components is printed to understand how much variance is captured by the components used.\n\n### Note\nYou can adjust the number of components in PCA to find the optimal number that balances complexity and model performance. More components may capture more variance but can also lead to overfitting. ","metadata":{}}]}