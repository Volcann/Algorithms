{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30775,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Logistic Regression\nLogistic Regression is a statistical method used for binary classification problems. It models the probability that a given input point belongs to a particular class. The output is a value between 0 and 1, which can be interpreted as a probability.","metadata":{}},{"cell_type":"code","source":"# Logistic Regression Notebook\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Generate synthetic binary classification data\nnp.random.seed(0)\nX = np.random.randn(100, 2)\ny = (X[:, 0] + X[:, 1] > 0).astype(int)  # Class 1 if the sum of the features is greater than 0\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n# Train the Logistic Regression model\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Predict using the model\ny_pred = model.predict(X_test)\n\n# Evaluate model performance\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred)\n\n# Print evaluation results\nprint(\"Accuracy:\", accuracy)\nprint(\"Confusion Matrix:\\n\", conf_matrix)\nprint(\"Classification Report:\\n\", class_report)\n\n# Visualize the results\nplt.scatter(X_test[y_test == 0][:, 0], X_test[y_test == 0][:, 1], color='red', label='Class 0')\nplt.scatter(X_test[y_test == 1][:, 0], X_test[y_test == 1][:, 1], color='blue', label='Class 1')\n\n# Create a mesh grid for decision boundary visualization\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\nZ = model.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\nplt.contourf(xx, yy, Z, alpha=0.3)\nplt.title('Logistic Regression Decision Boundary')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T06:00:57.169733Z","iopub.execute_input":"2024-10-01T06:00:57.170161Z","iopub.status.idle":"2024-10-01T06:00:59.269998Z","shell.execute_reply.started":"2024-10-01T06:00:57.170120Z","shell.execute_reply":"2024-10-01T06:00:59.268588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Explanation of Code Components\n\n1. **Data Generation**: Synthetic binary classification data is created. Points are classified as class 0 or class 1 based on whether the sum of two features is greater than 0.\n\n2. **Data Preprocessing**: The dataset is split into training and testing sets.\n\n3. **Model Training**: A Logistic Regression model is trained using the training data.\n\n4. **Prediction**: Predictions are made on the test set.\n\n5. **Model Evaluation**:\n   - **Accuracy**: The proportion of correctly classified instances.\n   - **Confusion Matrix**: A table used to describe the performance of the classification model.\n   - **Classification Report**: Includes precision, recall, and F1-score for each class.\n\n6. **Visualization**: A scatter plot shows the actual class distribution in the test set. The decision boundary created by the Logistic Regression model is visualized using contour plots.\n\n### Note\nYou can adjust the data generation process or the logistic regression parameters as needed. This implementation is straightforward and can be adapted for more complex datasets or multi-class classification problems.","metadata":{}}]}